## üß† Explicaci√≥n T√©cnica

La aplicaci√≥n usa una arquitectura **RAG (Retrieval-Augmented Generation)** para evitar enviar al modelo grandes porciones del repositorio de Cal.com. En lugar de intentar meter todo el contenido en el prompt, se indexa el c√≥digo de forma inteligente y solo se env√≠an los fragmentos realmente relevantes.

### 1. Indexaci√≥n del repositorio (pre-proceso)
- Se clona el repo p√∫blico `cal.com`.
- Usando **Tree-sitter**, se parsean archivos de m√∫ltiples extensiones (TS/JS/JSON, etc.) para extraer:
  - funciones  
  - clases  
  - imports/exports  
  - componentes y estructura  
- Cada fragmento significativo se convierte a **embedding** y se almacena en un **√≠ndice vectorial**.
- Esto se ejecuta una sola vez ‚Üí no se recalculan embeddings en tiempo de consulta.

### 2. Flujo de consulta

1) El usuario env√≠a un mensaje.  
2) El modelo analiza la consulta y decide si necesita hacer una b√∫squeda externa.  
   - Si requiere contexto del repositorio, genera el embedding de la consulta y puede invocar el **descriptionFileTool** para obtener fragmentos relevantes mediante b√∫squeda sem√°ntica.
   - Si la pregunta exige leer un archivo, listar una carpeta o buscar coincidencias exactas, puede elegir **contentFileTool**, **readFolderTool** o **findInRepoTool**.
   - Si no necesita informaci√≥n del repositorio, responde directamente sin usar herramientas.
3) Con la informaci√≥n recuperada (si la hay), el modelo construye un **prompt reducido**, que incluye solo los fragmentos esenciales y un resumen breve del historial reciente.
4) El modelo responde en **streaming**, manteniendo un contexto liviano y evitando cargar contenido innecesario del repositorio.

Este dise√±o permite que el agente consulte el repo √∫nicamente cuando la tarea lo demanda, combinando RAG sem√°ntico con herramientas de exploraci√≥n directa del c√≥digo sin saturar el l√≠mite de tokens.
